{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38132bit64e5c7e9c0ac4fd8934ae2d2769e2d28",
   "display_name": "Python 3.8.1 32-bit",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Sources and details of the dataset\n",
    "\n",
    "Foursquare is a social media platform where users can share their locations and rate venues. This dataset contains 09/2013's values.\n",
    "\n",
    "You need to download the dataset with torrent to access it.\n",
    "\n",
    "> https://archive.org/download/201309_foursquare_dataset_umn/201309_foursquare_dataset_umn_archive.torrent\n",
    "\n",
    "<img src=\"images/raw_dataset.png\">\n",
    "\n",
    "### [Content of Files](https://archive.org/details/201309_foursquare_dataset_umn)\n",
    "\n",
    " * users.dat: Consists of a set of users such that each user has a unique id and a geospatial location (latitude and longitude) that represents the user home town location.\n",
    " * venues.dat: Consists of a set of venues (e.g., restaurants) such that each venue has a unique id and a geospatial location (lattude and longitude).\n",
    " * checkins.dat: Marks the checkins (visits) of users at venues. Each check-in has a unique id as well as the user id and the venue id.\n",
    " * socialgraph.dat: Contains the social graph edges (connections) that exist between users. Each social connection consits of two users (friends) represented by two unique ids (first_user_id and second_user_id).\n",
    " * ratings.dat: Consists of implicit ratings that quantifies how much a user likes a specific venue.\n",
    "\n",
    "## A proposition on what, why and how to work with the data\n",
    "\n",
    "We don't have a clear hypothesis beforehand we will conduct exploratory analysis.\n",
    "\n",
    "### How we will work with foursquare dataset?\n",
    "\n",
    "  * Download dataset from source with torrent\n",
    "  * Clean and transform it with python\n",
    "  * Import it to PostgreSQL and design schema, tables and indexing for performance improvements.\n",
    "  * Analyze it with sql queries\n",
    "  * Visualize the results with python(i.e. matplotlib)\n",
    "  * Share the report and results with ipython notebook\n",
    "\n",
    "## Outline of the report\n",
    "\n",
    "* Introduction and details of the dataset.\n",
    "* Basic descriptive analysis of each table.\n",
    "* Social network analysis.\n",
    "* Reviewers and review activity analysis.\n",
    "* Venue popularity and rating analysis."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Accessing data from file system and cleaning it"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import time\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import filecmp\n",
    "\n",
    "source_dir = os.getcwd()\n",
    "raw_data_folder = source_dir+\"\\\\data\\\\raw\"\n",
    "clean_data_folder = source_dir+\"\\\\data\\\\clean\"\n",
    "\n",
    "for filename in filecmp.dircmp(raw_data_folder, clean_data_folder).common:\n",
    "    print(\"{filename} already exists.\".format(filename=filename))\n",
    "\n",
    "for filename in filecmp.dircmp(raw_data_folder, clean_data_folder).left_only: #this prevents processing already cleaned data, swap with below comment if you want to process it anyway\n",
    "#for filename in os.listdir(raw_data_folder):\n",
    "    with open(os.path.join(raw_data_folder, filename), 'r') as f: #open in readonly mode\n",
    "        start_time = math.trunc(time.time())\n",
    "        clean_file = open(os.path.join(clean_data_folder,filename),\"w\")\n",
    "        line_number = 0\n",
    "        for line in f:\n",
    "            line_number += 1 #Don't carry this to end of the elif statements otherwise line number will be zero indefinitely\n",
    "            if(line_number in range(1,3)):\n",
    "                #print(\"Deleted line: {line_number}\".format(line_number=line_number))\n",
    "                continue\n",
    "            elif(line.endswith(\"rows)\\n\")):\n",
    "                break\n",
    "            else:\n",
    "                clean_format = line.replace(\" \",\"\").replace(\"|\",\";\")\n",
    "                clean_file.write(clean_format)\n",
    "        clean_file.close()\n",
    "        end_time = math.trunc(time.time())\n",
    "        print(\"Cleaned and created {filename} in {execute_time} seconds\".format(execute_time=end_time-start_time, filename=filename))"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "checkins.dat already exists.\nratings.dat already exists.\nsocialgraph.dat already exists.\nusers.dat already exists.\nvenues.dat already exists.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Table ODS.EXT_FS_USERS already exists.\nTable ODS.EXT_FS_VENUES already exists.\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "pghost = \"localhost\"\n",
    "pguser = \"postgres\"\n",
    "pgdatabase = \"MEF-BDA-PROD\"\n",
    "pgport = \"5432\"\n",
    "pgpassword = \"123\"\n",
    "\n",
    "conn_string = 'host={pghost} port={pgport} dbname={pgdatabase} user={pguser} password={pgpassword}'.format(pgdatabase=pgdatabase,pguser=pguser,pgpassword=pgpassword,pghost=pghost,pgport=pgport)\n",
    "conn=psycopg2.connect(conn_string)\n",
    "cur=conn.cursor()\n",
    "\n",
    "def check_if_table_exists(schema,table):\n",
    "    cur.execute(\"select exists(select * from information_schema.tables where table_schema='{schema}' AND table_name='{table}')\".format(schema=schema, table=table))\n",
    "    return cur.fetchone()[0]\n",
    "\n",
    "def check_if_index_exists(index):\n",
    "    cur.execute(\"SELECT EXISTS(SELECT * FROM PG_CLASS WHERE relname = '{index}')\".format(index=index))\n",
    "    return cur.fetchone()[0]\n",
    "\n",
    "if(check_if_table_exists('ODS','EXT_FS_USERS')):\n",
    "    print('Table ODS.EXT_FS_USERS already exists.')   \n",
    "else:\n",
    "    start_time = math.trunc(time.time())\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE \"ODS\".\"EXT_FS_USERS\"\n",
    "    (\n",
    "    id integer,\n",
    "    latitude double precision,\n",
    "    longitude double precision\n",
    "    )\n",
    "\n",
    "    TABLESPACE pg_default;\n",
    "\n",
    "    ALTER TABLE \"ODS\".\"EXT_FS_USERS\"\n",
    "    OWNER to postgres;\n",
    "    \"\"\")\n",
    "    end_time = math.trunc(time.time())\n",
    "    cur.execute('COMMIT;')\n",
    "    print(\"Table ODS.EXT_FS_USERS created in {execute_time} seconds.\".format(execute_time=end_time-start_time))\n",
    "    \n",
    "    #start_time = math.trunc(time.time())\n",
    "    #cmd_command = \"\"\"\"C:\\\\Program Files\\\\PostgreSQL\\\\13\\\\bin\\\\psql.exe\" -h {pghost} -U {pguser} -d {pgdatabase} -p {pgport};\n",
    "    #{pgpassword}; \n",
    "    #\\COPY \"ODS\".\"EXT_FS_VENUES\" FROM '{datasource}' WITH (FORMAT CSV, DELIMITER ';');\n",
    "    #\"\"\".format(pgdatabase=pgdatabase,pguser=pguser,pgpassword=pgpassword,pghost=pghost,pgport=pgport,datasource=clean_data_folder.replace('\\\\','/')+\"/users.dat\")\n",
    "    #print(cmd_command)\n",
    "    #os.system('cmd /k {cmd_command}'.format(cmd_command=cmd_command))\n",
    "    #end_time = math.trunc(time.time())\n",
    "    #print(\"Imported data to ODS.EXT_FS_USERS in {execute_time} seconds.\".format(execute_time=end_time-start_time))\n",
    "\n",
    "if(check_if_table_exists('ODS','EXT_FS_VENUES')):\n",
    "    print('Table ODS.EXT_FS_VENUES already exists.')   \n",
    "else:\n",
    "    start_time = math.trunc(time.time())\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE \"ODS\".\"EXT_FS_VENUES\" AS \n",
    "    (\n",
    "    id integer,\n",
    "    latitude double precision,\n",
    "    longitude double precision\n",
    "    )\n",
    "    \n",
    "    TABLESPACE pg_default;\n",
    "\n",
    "    ALTER TABLE \"ODS\".\"EXT_FS_VENUES\"\n",
    "    OWNER to postgres;\n",
    "    \"\"\")\n",
    "    cur.execute('COMMIT;')\n",
    "    end_time = math.trunc(time.time())\n",
    "    print(\"Table ODS.EXT_FS_VENUES created in {execute_time} seconds.\".format(execute_time=end_time-start_time))"
   ]
  },
  {
   "source": [
    "cur.close()\n",
    "conn.close()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 5,
   "outputs": []
  },
  {
   "source": [
    "## Sources:\n",
    "\n",
    " 1. [Dataset](https://archive.org/details/201309_foursquare_dataset_umn)\n",
    "\n",
    " 2. [How to open every file in a folder?](https://stackoverflow.com/questions/18262293/how-to-open-every-file-in-a-folder)\n",
    "\n",
    " 3. [Python- reading a file line by line and processing](https://stackoverflow.com/questions/53749062/python-reading-a-file-line-by-line-and-processing)\n",
    "\n",
    " 4. [File and Directory Comparisons with Python](https://janakiev.com/blog/python-filecmp/)\n",
    "\n",
    " 5. [Checking if a table exist with psycopg2 on postgreSQL](https://stackoverflow.com/questions/1874113/checking-if-a-postgresql-table-exists-under-python-and-probably-psycopg2)\n",
    "\n",
    " 6. [Checking if index exist](https://stackoverflow.com/questions/45983169/checking-for-existence-of-index-in-postgresql)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}