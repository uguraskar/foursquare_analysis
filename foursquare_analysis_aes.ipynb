{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources and details of the dataset\n",
    "\n",
    "Foursquare is a social media platform where users can share their locations and rate venues. This dataset contains 09/2013's values.\n",
    "\n",
    "You need to download the dataset with torrent to access it.\n",
    "\n",
    "> https://archive.org/download/201309_foursquare_dataset_umn/201309_foursquare_dataset_umn_archive.torrent\n",
    "\n",
    "<img src=\"images/raw_dataset.png\">\n",
    "\n",
    "### [Content of Files](https://archive.org/details/201309_foursquare_dataset_umn)\n",
    "\n",
    " * users.dat: Consists of a set of users such that each user has a unique id and a geospatial location (latitude and longitude) that represents the user home town location.\n",
    " * venues.dat: Consists of a set of venues (e.g., restaurants) such that each venue has a unique id and a geospatial location (lattude and longitude).\n",
    " * checkins.dat: Marks the checkins (visits) of users at venues. Each check-in has a unique id as well as the user id and the venue id.\n",
    " * socialgraph.dat: Contains the social graph edges (connections) that exist between users. Each social connection consists of two users (friends) represented by two unique ids (first_user_id and second_user_id).\n",
    " * ratings.dat: Consists of implicit ratings that quantifies how much a user likes a specific venue.\n",
    "\n",
    "## A proposition on what, why and how to work with the data\n",
    "\n",
    "We don't have a clear hypothesis beforehand we will conduct exploratory analysis.\n",
    "\n",
    "### How we will work with foursquare dataset?\n",
    "\n",
    "  * Download dataset from source with torrent\n",
    "  * Clean and transform it with python\n",
    "  * Import it to PostgreSQL and design schema, tables and indexing for performance improvements.\n",
    "  * Analyze it with sql queries\n",
    "  * Visualize the results with python(i.e. matplotlib)\n",
    "  * Share the report and results with ipython notebook\n",
    "\n",
    "## Outline of the report\n",
    "\n",
    "* Introduction and details of the dataset.\n",
    "* Basic descriptive analysis of each table.\n",
    "* Social network analysis.\n",
    "* Reviewers and review activity analysis.\n",
    "* Venue popularity and rating analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing data from file system and cleaning it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Sistem belirtilen yolu bulamıyor: 'C:\\\\Users\\\\ahmet\\\\Desktop\\\\Data-ML\\\\MEF-BDA\\\\BDA-505\\\\github_fs\\\\data\\\\raw'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9ec045fcbfa7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mclean_data_folder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msource_dir\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"\\\\data\\\\clean\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfilecmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdircmp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_data_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclean_data_folder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{filename} already exists.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\filecmp.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    245\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mattr\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethodmap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethodmap\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\filecmp.py\u001b[0m in \u001b[0;36mphase1\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mphase1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# Compute common names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormcase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormcase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__contains__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\filecmp.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    245\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mattr\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethodmap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethodmap\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\filecmp.py\u001b[0m in \u001b[0;36mphase0\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mphase0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# Compare everything except common subdirectories\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m         self.left_list = _filter(os.listdir(self.left),\n\u001b[0m\u001b[0;32m    134\u001b[0m                                  self.hide+self.ignore)\n\u001b[0;32m    135\u001b[0m         self.right_list = _filter(os.listdir(self.right),\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Sistem belirtilen yolu bulamıyor: 'C:\\\\Users\\\\ahmet\\\\Desktop\\\\Data-ML\\\\MEF-BDA\\\\BDA-505\\\\github_fs\\\\data\\\\raw'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import filecmp\n",
    "\n",
    "source_dir = os.getcwd()\n",
    "raw_data_folder = source_dir+\"\\\\data\\\\raw\"\n",
    "clean_data_folder = source_dir+\"\\\\data\\\\clean\"\n",
    "\n",
    "for filename in filecmp.dircmp(raw_data_folder, clean_data_folder).common:\n",
    "    print(\"{filename} already exists.\".format(filename=filename))\n",
    "\n",
    "for filename in filecmp.dircmp(raw_data_folder, clean_data_folder).left_only: #this prevents processing already cleaned data, swap with below comment if you want to process it anyway\n",
    "#for filename in os.listdir(raw_data_folder):\n",
    "    with open(os.path.join(raw_data_folder, filename), 'r') as f: #open in readonly mode\n",
    "        start_time = math.trunc(time.time())\n",
    "        clean_file = open(os.path.join(clean_data_folder,filename),\"w\")\n",
    "        line_number = 0\n",
    "        for line in f:\n",
    "            line_number += 1 #Don't carry this to end of the elif statements otherwise line number will be zero indefinitely\n",
    "            if(line_number in range(1,3)):\n",
    "                #print(\"Deleted line: {line_number}\".format(line_number=line_number))\n",
    "                continue\n",
    "            elif(line.endswith(\"rows)\\n\")):\n",
    "                break\n",
    "            else:\n",
    "                clean_format = line.replace(\" \",\"\").replace(\"|\",\";\")\n",
    "                clean_file.write(clean_format)\n",
    "        clean_file.close()\n",
    "        end_time = math.trunc(time.time())\n",
    "        print(\"Cleaned and created {filename} in {execute_time} seconds\".format(execute_time=end_time-start_time, filename=filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table ODS.EXT_FS_USERS already exists.\n",
      "Table ODS.EXT_FS_VENUES already exists.\n",
      "Table ODS.EXT_FS_SOCIALGRAPH already exists.\n",
      "Table ODS.EXT_FS_RATINGS already exists.\n",
      "Table ODS.EXT_FS_CHECKINS already exists.\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "pghost = \"localhost\"\n",
    "pguser = \"postgres\"\n",
    "pgdatabase = \"MEF-BDA-PROD\"\n",
    "pgport = \"5432\"\n",
    "pgpassword = \"123\"\n",
    "#Normally you shouldn't keep database connections in your source code but this one is ok because we are only going to work in local.\n",
    "\n",
    "conn_string = 'host={pghost} port={pgport} dbname={pgdatabase} user={pguser} password={pgpassword}'.format(pgdatabase=pgdatabase,pguser=pguser,pgpassword=pgpassword,pghost=pghost,pgport=pgport)\n",
    "conn=psycopg2.connect(conn_string)\n",
    "cur=conn.cursor()\n",
    "\n",
    "def check_if_table_exists(schema,table):\n",
    "    cur.execute(\"select exists(select * from information_schema.tables where table_schema='{schema}' AND table_name='{table}')\".format(schema=schema, table=table))\n",
    "    return cur.fetchone()[0]\n",
    "\n",
    "def check_if_index_exists(index):\n",
    "    cur.execute(\"SELECT EXISTS(SELECT * FROM PG_CLASS WHERE relname = '{index}')\".format(index=index))\n",
    "    return cur.fetchone()[0]\n",
    "\n",
    "if(check_if_table_exists('ODS','EXT_FS_USERS')):\n",
    "    print('Table ODS.EXT_FS_USERS already exists.')   \n",
    "else:\n",
    "    start_time = math.trunc(time.time())\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE \"ODS\".\"EXT_FS_USERS\"\n",
    "    (\n",
    "    id integer,\n",
    "    latitude double precision,\n",
    "    longitude double precision\n",
    "    )\n",
    "\n",
    "    TABLESPACE pg_default;\n",
    "\n",
    "    ALTER TABLE \"ODS\".\"EXT_FS_USERS\"\n",
    "    OWNER to postgres;\n",
    "    \"\"\")\n",
    "    end_time = math.trunc(time.time())\n",
    "    cur.execute('COMMIT;')\n",
    "    print(\"Table ODS.EXT_FS_USERS created in {execute_time} seconds.\".format(execute_time=end_time-start_time))\n",
    "\n",
    "if(check_if_table_exists('ODS','EXT_FS_VENUES')):\n",
    "    print('Table ODS.EXT_FS_VENUES already exists.')   \n",
    "else:\n",
    "    start_time = math.trunc(time.time())\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE \"ODS\".\"EXT_FS_VENUES\"\n",
    "    (\n",
    "    id integer,\n",
    "    latitude double precision,\n",
    "    longitude double precision\n",
    "    )\n",
    "    \n",
    "    TABLESPACE pg_default;\n",
    "\n",
    "    ALTER TABLE \"ODS\".\"EXT_FS_VENUES\"\n",
    "    OWNER to postgres;\n",
    "    \"\"\")\n",
    "    cur.execute('COMMIT;')\n",
    "    end_time = math.trunc(time.time())\n",
    "    print(\"Table ODS.EXT_FS_VENUES created in {execute_time} seconds.\".format(execute_time=end_time-start_time))\n",
    "\n",
    "if(check_if_table_exists('ODS','EXT_FS_SOCIALGRAPH')):\n",
    "    print('Table ODS.EXT_FS_SOCIALGRAPH already exists.')   \n",
    "else:\n",
    "    start_time = math.trunc(time.time())\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE \"ODS\".\"EXT_FS_SOCIALGRAPH\"\n",
    "    (\n",
    "    first_user_id integer,\n",
    "    second_user_id integer\n",
    "    )\n",
    "\n",
    "    TABLESPACE pg_default;\n",
    "\n",
    "    ALTER TABLE \"ODS\".\"EXT_FS_SOCIALGRAPH\"\n",
    "    OWNER to postgres;\n",
    "    \"\"\")\n",
    "    end_time = math.trunc(time.time())\n",
    "    cur.execute('COMMIT;')\n",
    "    print(\"Table ODS.EXT_FS_SOCIALGRAPH created in {execute_time} seconds.\".format(execute_time=end_time-start_time))\n",
    "\n",
    "if(check_if_table_exists('ODS','EXT_FS_RATINGS')):\n",
    "    print('Table ODS.EXT_FS_RATINGS already exists.')   \n",
    "else:\n",
    "    start_time = math.trunc(time.time())\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE \"ODS\".\"EXT_FS_RATINGS\"\n",
    "    (\n",
    "    user_id integer,\n",
    "    venue_id integer,\n",
    "    rating integer\n",
    "    )\n",
    "\n",
    "    TABLESPACE pg_default;\n",
    "\n",
    "    ALTER TABLE \"ODS\".\"EXT_FS_RATINGS\"\n",
    "    OWNER to postgres;\n",
    "    \"\"\")\n",
    "    end_time = math.trunc(time.time())\n",
    "    cur.execute('COMMIT;')\n",
    "    print(\"Table ODS.EXT_FS_RATINGS created in {execute_time} seconds.\".format(execute_time=end_time-start_time))\n",
    "\n",
    "if(check_if_table_exists('ODS','EXT_FS_CHECKINS')):\n",
    "    print('Table ODS.EXT_FS_CHECKINS already exists.')   \n",
    "else:\n",
    "    start_time = math.trunc(time.time())\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE \"ODS\".\"EXT_FS_CHECKINS\"\n",
    "    (\n",
    "    id integer,\n",
    "    user_id integer,\n",
    "    venue_id integer,\n",
    "    latitude double precision,\n",
    "    longitude double precision,\n",
    "    created_at text COLLATE pg_catalog.\"default\"\n",
    "    )\n",
    "\n",
    "    TABLESPACE pg_default;\n",
    "\n",
    "    ALTER TABLE \"ODS\".\"EXT_FS_CHECKINS\"\n",
    "    OWNER to postgres;\n",
    "    \"\"\")\n",
    "    end_time = math.trunc(time.time())\n",
    "    cur.execute('COMMIT;')\n",
    "    print(\"Table ODS.EXT_FS_CHECKINS created in {execute_time} seconds.\".format(execute_time=end_time-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets import the data with;\n",
    "\n",
    "```postgresql\n",
    "\\COPY \"ODS\".\"EXT_FS_USERS\" FROM '[FilePath]/users.dat' WITH (FORMAT CSV, DELIMITER ';');\n",
    "\\COPY \"ODS\".\"EXT_FS_VENUES\" FROM '[FilePath]/venues.dat' WITH (FORMAT CSV, DELIMITER ';', FORCE_NULL(latitude,longitude));\n",
    "\\COPY \"ODS\".\"EXT_FS_SOCIALGRAPH\" FROM '[FilePath]/socialgraph.dat' WITH (FORMAT CSV, DELIMITER ';');\n",
    "\\COPY \"ODS\".\"EXT_FS_RATINGS\" FROM '[FilePath]/ratings.dat' WITH (FORMAT CSV, DELIMITER ';');\n",
    "\\COPY \"ODS\".\"EXT_FS_CHECKINS\" FROM '[FilePath]/checkins.dat' WITH (FORMAT CSV, DELIMITER ';');\n",
    "``` \n",
    "\n",
    "**You should use PSQL(SQL Shell) instead of IDE because \\COPY command only works there, also \\COPY command should not be mistaken with COPY command.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We imported foursquare data to postgresql tables but there is a one thing we should do before proceeding to work with it.\n",
    "\n",
    "There was an issue while importing date time values so we imported them as text values, we can create a new table with;\n",
    "\n",
    "```postgresql\n",
    "CREATE TABLE TABLE_NAME AS\n",
    "SELECT * \n",
    "FROM OLD_TABLE_NAME; \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table EDW.EXT_FS_CHECKINS already exists.\n"
     ]
    }
   ],
   "source": [
    "if(check_if_table_exists('EDW','EXT_FS_CHECKINS')):\n",
    "    print('Table EDW.EXT_FS_CHECKINS already exists.')   \n",
    "else:\n",
    "    start_time = math.trunc(time.time())\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE \"EDW\".\"EXT_FS_CHECKINS\" AS\n",
    "    SELECT\n",
    "    id,\n",
    "    user_id,\n",
    "    venue_id,\n",
    "    latitude,\n",
    "    longitude,\n",
    "    to_timestamp(created_at, 'YYYY-MM-DDhh24:mi:ss') AS created_at\n",
    "    FROM \"ODS\".\"EXT_FS_CHECKINS\";\n",
    "    \"\"\")\n",
    "    end_time = math.trunc(time.time())\n",
    "    cur.execute('COMMIT;')\n",
    "    print(\"Table EDW.EXT_FS_CHECKINS created in {execute_time} seconds.\".format(execute_time=end_time-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis and Visualization\n",
    "\n",
    "## Most 200 ranked venues\n",
    "\n",
    "In this example we are going to look at most 200 ranked venues which have at least 20 ratings by users and visualize it in basemap library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table EDW.DWH_VENUE_RATINGS created in 5 seconds.\n",
      "Index IDX_DWH_VENUE_RATINGS#01 created in 1 seconds\n"
     ]
    }
   ],
   "source": [
    "if(check_if_table_exists('EDW','DWH_VENUE_RATINGS')):\n",
    "    print('Table EDW.DWH_VENUE_RATINGS already exists.')   \n",
    "else:\n",
    "    start_time = math.trunc(time.time())\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE \"EDW\".\"DWH_VENUE_RATINGS\" AS\n",
    "    SELECT\n",
    "    venue_id,\n",
    "    AVG(rating) AS average_rating,\n",
    "    COUNT(*) AS total_ratings,\n",
    "    VNS.latitude,\n",
    "    VNS.longitude\n",
    "    FROM \"ODS\".\"EXT_FS_RATINGS\" RTG\n",
    "    INNER JOIN \"ODS\".\"EXT_FS_VENUES\" VNS ON (RTG.venue_id = VNS.id)\n",
    "    WHERE 1=1\n",
    "    AND VNS.latitude IS NOT NULL\n",
    "    AND VNS.longitude IS NOT NULL\n",
    "    GROUP BY RTG.venue_id,\n",
    "    VNS.latitude,\n",
    "    VNS.longitude\n",
    "    \"\"\")\n",
    "    end_time = math.trunc(time.time())\n",
    "    cur.execute('COMMIT;')\n",
    "    print(\"Table EDW.DWH_VENUE_RATINGS created in {execute_time} seconds.\".format(execute_time=end_time-start_time))\n",
    "\n",
    "if(check_if_index_exists('IDX_DWH_VENUE_RATINGS#01')):\n",
    "    print('Index IDX_DWH_VENUE_RATINGS#01 already exists')\n",
    "else:\n",
    "    start_time = math.trunc(time.time())\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE INDEX \"IDX_DWH_VENUE_RATINGS#01\"\n",
    "    ON \"EDW\".\"DWH_VENUE_RATINGS\" USING btree\n",
    "    (total_ratings ASC NULLS LAST)\n",
    "    ;\n",
    "    \"\"\")\n",
    "    end_time = math.trunc(time.time())\n",
    "    cur.execute('COMMIT;')\n",
    "    print(\"Index IDX_DWH_VENUE_RATINGS#01 created in {execute_time} seconds\".format(execute_time=end_time-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>venue_id</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>total_ratings</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>407336</td>\n",
       "      <td>4.006897</td>\n",
       "      <td>145</td>\n",
       "      <td>42.494700</td>\n",
       "      <td>-71.188600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>957067</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>68</td>\n",
       "      <td>42.494700</td>\n",
       "      <td>-71.188600</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5732</td>\n",
       "      <td>3.986301</td>\n",
       "      <td>73</td>\n",
       "      <td>36.145361</td>\n",
       "      <td>-115.179806</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>111995</td>\n",
       "      <td>3.933333</td>\n",
       "      <td>105</td>\n",
       "      <td>42.745885</td>\n",
       "      <td>-71.109502</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9883</td>\n",
       "      <td>3.886700</td>\n",
       "      <td>203</td>\n",
       "      <td>32.707000</td>\n",
       "      <td>-117.161851</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>417</td>\n",
       "      <td>3.881773</td>\n",
       "      <td>203</td>\n",
       "      <td>40.735164</td>\n",
       "      <td>-74.004691</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>13116</td>\n",
       "      <td>3.818182</td>\n",
       "      <td>77</td>\n",
       "      <td>40.725135</td>\n",
       "      <td>-74.002087</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>33197</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>60</td>\n",
       "      <td>37.796661</td>\n",
       "      <td>-122.422051</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>15193</td>\n",
       "      <td>3.698276</td>\n",
       "      <td>116</td>\n",
       "      <td>40.743095</td>\n",
       "      <td>-73.988457</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>19778</td>\n",
       "      <td>3.692308</td>\n",
       "      <td>52</td>\n",
       "      <td>40.752117</td>\n",
       "      <td>-74.008691</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>21655</td>\n",
       "      <td>3.634615</td>\n",
       "      <td>104</td>\n",
       "      <td>40.730901</td>\n",
       "      <td>-73.992115</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>162047</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>56</td>\n",
       "      <td>40.736218</td>\n",
       "      <td>-73.997920</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>10084</td>\n",
       "      <td>3.569444</td>\n",
       "      <td>72</td>\n",
       "      <td>40.691182</td>\n",
       "      <td>-74.016781</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>264517</td>\n",
       "      <td>3.540000</td>\n",
       "      <td>50</td>\n",
       "      <td>39.097528</td>\n",
       "      <td>-84.507040</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>15283</td>\n",
       "      <td>3.532110</td>\n",
       "      <td>109</td>\n",
       "      <td>-6.170849</td>\n",
       "      <td>106.824145</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>9829</td>\n",
       "      <td>3.523077</td>\n",
       "      <td>65</td>\n",
       "      <td>40.756620</td>\n",
       "      <td>-74.001760</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>67599</td>\n",
       "      <td>3.520000</td>\n",
       "      <td>50</td>\n",
       "      <td>37.764372</td>\n",
       "      <td>-122.431205</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1002</td>\n",
       "      <td>3.515152</td>\n",
       "      <td>66</td>\n",
       "      <td>40.764080</td>\n",
       "      <td>-73.973136</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>99516</td>\n",
       "      <td>3.461538</td>\n",
       "      <td>91</td>\n",
       "      <td>40.725503</td>\n",
       "      <td>-73.991976</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>197955</td>\n",
       "      <td>3.457447</td>\n",
       "      <td>188</td>\n",
       "      <td>34.112240</td>\n",
       "      <td>-118.338654</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    venue_id  average_rating  total_ratings   latitude   longitude  order\n",
       "0     407336        4.006897            145  42.494700  -71.188600      1\n",
       "1     957067        4.000000             68  42.494700  -71.188600      2\n",
       "2       5732        3.986301             73  36.145361 -115.179806      3\n",
       "3     111995        3.933333            105  42.745885  -71.109502      4\n",
       "4       9883        3.886700            203  32.707000 -117.161851      5\n",
       "5        417        3.881773            203  40.735164  -74.004691      6\n",
       "6      13116        3.818182             77  40.725135  -74.002087      7\n",
       "7      33197        3.800000             60  37.796661 -122.422051      8\n",
       "8      15193        3.698276            116  40.743095  -73.988457      9\n",
       "9      19778        3.692308             52  40.752117  -74.008691     10\n",
       "10     21655        3.634615            104  40.730901  -73.992115     11\n",
       "11    162047        3.625000             56  40.736218  -73.997920     12\n",
       "12     10084        3.569444             72  40.691182  -74.016781     13\n",
       "13    264517        3.540000             50  39.097528  -84.507040     14\n",
       "14     15283        3.532110            109  -6.170849  106.824145     15\n",
       "15      9829        3.523077             65  40.756620  -74.001760     16\n",
       "16     67599        3.520000             50  37.764372 -122.431205     17\n",
       "17      1002        3.515152             66  40.764080  -73.973136     18\n",
       "18     99516        3.461538             91  40.725503  -73.991976     19\n",
       "19    197955        3.457447            188  34.112240 -118.338654     20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sql_command = \"\"\"\n",
    "WITH RD AS(\n",
    "SELECT VR.*,\n",
    "RANK() OVER(ORDER BY average_rating DESC, total_ratings DESC, venue_id) AS ORDER\n",
    "FROM \"EDW\".\"DWH_VENUE_RATINGS\" VR\n",
    "WHERE 1=1\n",
    "AND VR.total_ratings >= 50\n",
    ")\n",
    "SELECT * \n",
    "FROM RD\n",
    "ORDER BY RD.order\n",
    "LIMIT 200;\n",
    "\"\"\"\n",
    "df_venue_ratings = pd.read_sql(sql_command,conn)\n",
    "df_venue_ratings.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'PROJ_LIB'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-0a3036182340>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmpl_toolkits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasemap\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBasemap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\mpl_toolkits\\basemap\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[1;31m# create dictionary that maps epsg codes to Basemap kwargs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m \u001b[0mpyproj_datadir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'PROJ_LIB'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m \u001b[0mepsgf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyproj_datadir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'epsg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[0mepsg_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    676\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m             \u001b[1;31m# raise KeyError with the original key value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'PROJ_LIB'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "m = Basemap(projection='ortho', resolution=None, lat_0=df_venue_ratings['latitude'][0], lon_0=df_venue_ratings['longitude'][0],)\n",
    "\n",
    "for c in df_venue_ratings['order']:\n",
    "    i = c-1\n",
    "    x, y = m(df_venue_ratings['longitude'][i], df_venue_ratings['latitude'][i])\n",
    "    plt.plot(x, y, 'co', markersize= df_venue_ratings['average_rating'][i])\n",
    "\n",
    "m.bluemarble()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popular_situation</th>\n",
       "      <th>venue_id</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>venue_checkings_number</th>\n",
       "      <th>venue_ratings_num</th>\n",
       "      <th>row_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Asocial</td>\n",
       "      <td>33177</td>\n",
       "      <td>3.00</td>\n",
       "      <td>115.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Asocial</td>\n",
       "      <td>6339</td>\n",
       "      <td>2.99</td>\n",
       "      <td>86.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Asocial</td>\n",
       "      <td>73804</td>\n",
       "      <td>2.93</td>\n",
       "      <td>66.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Average</td>\n",
       "      <td>501132</td>\n",
       "      <td>5.00</td>\n",
       "      <td>54.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Average</td>\n",
       "      <td>110033</td>\n",
       "      <td>5.00</td>\n",
       "      <td>74.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Average</td>\n",
       "      <td>94278</td>\n",
       "      <td>5.00</td>\n",
       "      <td>121.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Not Popular</td>\n",
       "      <td>46646</td>\n",
       "      <td>5.00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Not Popular</td>\n",
       "      <td>565838</td>\n",
       "      <td>4.50</td>\n",
       "      <td>50.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Not Popular</td>\n",
       "      <td>333967</td>\n",
       "      <td>4.33</td>\n",
       "      <td>59.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Popular</td>\n",
       "      <td>112490</td>\n",
       "      <td>5.00</td>\n",
       "      <td>75.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Popular</td>\n",
       "      <td>893127</td>\n",
       "      <td>5.00</td>\n",
       "      <td>58.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Popular</td>\n",
       "      <td>893113</td>\n",
       "      <td>5.00</td>\n",
       "      <td>62.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Very Popular</td>\n",
       "      <td>119463</td>\n",
       "      <td>5.00</td>\n",
       "      <td>116.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Very Popular</td>\n",
       "      <td>584943</td>\n",
       "      <td>4.50</td>\n",
       "      <td>103.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Very Popular</td>\n",
       "      <td>52301</td>\n",
       "      <td>4.00</td>\n",
       "      <td>121.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   popular_situation  venue_id  avg_rating  venue_checkings_number  \\\n",
       "0            Asocial     33177        3.00                   115.0   \n",
       "1            Asocial      6339        2.99                    86.0   \n",
       "2            Asocial     73804        2.93                    66.0   \n",
       "3            Average    501132        5.00                    54.0   \n",
       "4            Average    110033        5.00                    74.0   \n",
       "5            Average     94278        5.00                   121.0   \n",
       "6        Not Popular     46646        5.00                    50.0   \n",
       "7        Not Popular    565838        4.50                    50.0   \n",
       "8        Not Popular    333967        4.33                    59.0   \n",
       "9            Popular    112490        5.00                    75.0   \n",
       "10           Popular    893127        5.00                    58.0   \n",
       "11           Popular    893113        5.00                    62.0   \n",
       "12      Very Popular    119463        5.00                   116.0   \n",
       "13      Very Popular    584943        4.50                   103.0   \n",
       "14      Very Popular     52301        4.00                   121.0   \n",
       "\n",
       "    venue_ratings_num  row_num  \n",
       "0               318.0        1  \n",
       "1               307.0        2  \n",
       "2               128.0        3  \n",
       "3                55.0        1  \n",
       "4                83.0        2  \n",
       "5               136.0        3  \n",
       "6                51.0        1  \n",
       "7                52.0        2  \n",
       "8                62.0        3  \n",
       "9                77.0        1  \n",
       "10               59.0        2  \n",
       "11               63.0        3  \n",
       "12              122.0        1  \n",
       "13              105.0        2  \n",
       "14              168.0        3  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sql_command = \"\"\"\n",
    "SELECT *\n",
    "FROM\n",
    "(\n",
    "\tSELECT popular_situation, venue_id, avg_rating, venue_checkings_number, venue_ratings_num,\n",
    "\t\tROW_NUMBER() OVER(PARTITION BY popular_situation ORDER BY avg_rating desc) AS row_num\n",
    "\tFROM\n",
    "\t(\n",
    "\t\tSELECT popular_situation, venue_id, ROUND(AVG(rating),2) AS avg_rating, \n",
    "\t\t\tROUND(AVG(venue_checkings_number),0) as venue_checkings_number, \n",
    "\t\t\tROUND(AVG(venue_ratings_num),0) as venue_ratings_num\n",
    "\t\tFROM\n",
    "\t\t(\n",
    "\t\t\tWITH socialism_dt AS\n",
    "\t\t\t(\n",
    "\t\t\tSELECT user_id, friends_num, \n",
    "\t\t\t\tCASE\n",
    "\t\t\t\t WHEN friends_num > 10000 THEN 'Very Popular'\n",
    "\t\t\t\t WHEN (friends_num <= 10000) AND (friends_num > 1000) THEN 'Popular'\n",
    "\t\t\t\t WHEN (friends_num <= 1000) AND (friends_num > 200) THEN 'Average'\n",
    "\t\t\t\t WHEN (friends_num <= 200) AND (friends_num > 20) THEN 'Not Popular'\n",
    "\t\t\t\t WHEN (friends_num <= 20) AND (friends_num > 0) THEN 'Asocial' \n",
    "\t\t\t\tEND AS popular_situation\n",
    "\t\t\tFROM\n",
    "\t\t\t(\n",
    "\t\t\t\tSELECT first_user_id AS user_id, COUNT(*) AS friends_num\n",
    "\t\t\t\tFROM \"ODS\".\"EXT_FS_SOCIALGRAPH\"\n",
    "\t\t\t\tGROUP BY first_user_id\n",
    "\t\t\t) AS dt3\n",
    "\t\t\t),\n",
    "\t\t\tratings_pop AS\n",
    "\t\t\t(\n",
    "\t\t\tSELECT fr.*, s.friends_num, s.popular_situation\n",
    "\t\t\tFROM \"ODS\".\"EXT_FS_RATINGS\" AS fr\n",
    "\t\t\tLEFT JOIN socialism_dt AS s\n",
    "\t\t\tON s.user_id = fr.user_id\n",
    "\t\t\t),\n",
    "\t\t\tvenue_ratings AS\n",
    "\t\t\t(\n",
    "\t\t\tSELECT venue_id, COUNT(*) AS venue_ratings_num\n",
    "\t\t\tFROM \"ODS\".\"EXT_FS_RATINGS\"\n",
    "\t\t\tGROUP BY venue_id\n",
    "\t\t\t),\n",
    "\t\t\tvenue_checkings AS\n",
    "\t\t\t(\n",
    "\t\t\tSELECT venue_id, COUNT(*) AS venue_checkings_number\n",
    "\t\t\tFROM \"EDW\".\"EXT_FS_CHECKINS\"\n",
    "\t\t\tGROUP BY venue_id\n",
    "\t\t\t)\n",
    "\t\t\tSELECT rp.*, vc.venue_checkings_number, vr.venue_ratings_num \n",
    "\t\t\tFROM ratings_pop AS rp\n",
    "\t\t\tLEFT JOIN venue_checkings AS vc ON rp.venue_id = vc.venue_id\n",
    "\t\t\tLEFT JOIN venue_ratings AS vr ON vr.venue_id = rp.venue_id\n",
    "\t\t\tWHERE vc.venue_checkings_number > 49\n",
    "\t\t\tAND vr.venue_ratings_num>49\n",
    "\t\t) AS dt4\n",
    "\t\tGROUP BY popular_situation, venue_id\n",
    "\t) AS dt5\n",
    ") AS dt6\n",
    "WHERE row_num < 4\n",
    "AND popular_situation IS NOT NULL\n",
    "ORDER BY popular_situation, avg_rating desc\n",
    "LIMIT 20;\n",
    "\"\"\"\n",
    "df = pd.read_sql(sql_command,conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cur.close()\n",
    "#conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources:\n",
    "\n",
    " 1. [Dataset](https://archive.org/details/201309_foursquare_dataset_umn)\n",
    "\n",
    " 2. [How to open every file in a folder?](https://stackoverflow.com/questions/18262293/how-to-open-every-file-in-a-folder)\n",
    "\n",
    " 3. [Python- reading a file line by line and processing](https://stackoverflow.com/questions/53749062/python-reading-a-file-line-by-line-and-processing)\n",
    "\n",
    " 4. [File and Directory Comparisons with Python](https://janakiev.com/blog/python-filecmp/)\n",
    "\n",
    " 5. [Checking if a table exist with psycopg2 on postgreSQL](https://stackoverflow.com/questions/1874113/checking-if-a-postgresql-table-exists-under-python-and-probably-psycopg2)\n",
    "\n",
    " 6. [Checking if index exist](https://stackoverflow.com/questions/45983169/checking-for-existence-of-index-in-postgresql)\n",
    "\n",
    " 7. [Download basemap](https://www.lfd.uci.edu/~gohlke/pythonlibs/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
